{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\30. Open Source llm -RAG\\Knowledge-Hub-Assistant\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "from uuid import uuid4\n",
    "import shutil\n",
    "\n",
    "\n",
    "# from langchain_elasticsearch import ElasticsearchStore\n",
    "from werkzeug.utils import secure_filename\n",
    "import tempfile\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "# from langchain_core.documents import Document\n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "# from services.sql_connection import sql_connect\n",
    "# import sqlite3\n",
    "\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from unstructured.partition.docx import partition_docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_retrieval_chunking(file_path):\n",
    "\ttry:\n",
    "\t\tif file_path.endswith(\".pdf\"):\n",
    "\t\t\tprint(\"--------------PDF FILE DETECTED-------------\")\n",
    "\t\t\tchunks = partition_pdf(\n",
    "\t\t\t\tfilename=file_path,\n",
    "\t\t\t\tinfer_table_structure=True,  # extract tables\n",
    "\t\t\t\tstrategy=\"hi_res\",  # mandatory to infer tables\n",
    "\t\t\t\textract_image_block_types=[\n",
    "\t\t\t\t\t\"Image\"\n",
    "\t\t\t\t],  # Add 'Table' to list to extract image of tables\n",
    "\t\t\t\t# image_output_dir_path=output_path,  # if None, images and tables will saved in base64\n",
    "\t\t\t\textract_image_block_to_payload=True,  # if true, will extract base64 for API usage\n",
    "\t\t\t\tchunking_strategy=\"by_title\",  # or 'basic', by_page - api\n",
    "\t\t\t\tmax_characters=10000,  # defaults to 500\n",
    "\t\t\t\tcombine_text_under_n_chars=2000,  # defaults to 0\n",
    "\t\t\t\tnew_after_n_chars=6000,\n",
    "\t\t\t\t# extract_images_in_pdf=True,          # deprecated\n",
    "\t\t\t)\n",
    "\t\t\tprint(chunks)\n",
    "\t\t\treturn chunks\n",
    "\t\telif file_path.endswith(\".docx\"):\n",
    "\t\t\tprint(\"--------------DOCX FILE DETECTED-------------\")\n",
    "\t\t\tchunks = partition_docx(filename=file_path,\n",
    "                        strategy=\"hi_res\",\n",
    "                        infer_table_structure=True, \n",
    "                        include_page_breaks=True,\n",
    "                        extract_image_block_types=[\"Image\"], \n",
    "                        extract_image_block_to_payload=True,\n",
    "                        chunking_strategy=\"by_title\",\n",
    "                        max_characters=10000,\n",
    "                        combine_text_under_n_chars=2000,  # defaults to 0\n",
    "                        new_after_n_chars=6000)\n",
    "\t\t\tprint(chunks)\n",
    "\t\t\treturn chunks\n",
    "\texcept Exception as e:\n",
    "\t\tprint(\"partition error ::\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_processing(chunks,file_name,domain):\n",
    "\tlist1=[]\n",
    "\tchunk_ids=[]\n",
    "\tfor id, chunk in enumerate(chunks):\n",
    "\t\tchunk_dict = chunk.to_dict()\n",
    "\t\telements = chunk.metadata.orig_elements\n",
    "\t\tchunk_images = [el.to_dict() for el in elements if \"Image\" in str(type(el))]\n",
    "\t\t# Preparing the Chunk \n",
    "\t\titem = {}\n",
    "\n",
    "\t\tif \"metadata\" not in item.keys():\n",
    "\t\t\titem['metadata']={}\n",
    "\n",
    "\t\t# Check the table is in the chunk, is yes add into the text context\n",
    "\t\tif \"Table\" in str(elements):\n",
    "\t\t\titem[\"page_content\"] = (\n",
    "\t\t\t\tchunk_dict[\"text\"]\n",
    "\t\t\t\t+ \"Table in Html format :\"\n",
    "\t\t\t\t+ chunk_dict[\"metadata\"][\"text_as_html\"]\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\titem[\"page_content\"] = chunk_dict[\"text\"]\n",
    "\n",
    "\t\t# Assigning the chunk ids to document chunk\n",
    "\t\titem[\"metadata\"][\"chunk_id\"] = file_name + f\"_{id}\"\n",
    "\t\tchunk_ids.append(item[\"metadata\"][\"chunk_id\"])\n",
    "\t\t# File Metadata\n",
    "\t\titem[\"metadata\"][\"filename\"] = chunk_dict[\"metadata\"][\"filename\"]\n",
    "\t\titem[\"metadata\"][\"element_id\"] = chunk_dict[\"element_id\"]\n",
    "\t\titem[\"metadata\"]['domain']=domain\n",
    "\t\t\t\n",
    "\t\tif \"page_number\" in chunk_dict[\"metadata\"].keys():\n",
    "\t\t\titem[\"metadata\"][\"page_number\"] = str(chunk_dict[\"metadata\"][\"page_number\"])\n",
    "\t\telse:\n",
    "\t\t\titem[\"metadata\"][\"page_number\"] = \"NA\"\n",
    "\t\t\n",
    "\t\tif chunk_images:\n",
    "\t\t\titem[\"metadata\"][\"images_info\"] = str(\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"image_associated_text\": i[\"text\"],\n",
    "\t\t\t\t\t\t\"image_base64\": i[\"metadata\"][\"image_base64\"],\n",
    "\t\t\t\t\t\t\"images_link\": \"\",\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t\tfor i in chunk_images\n",
    "\t\t\t\t]\n",
    "\t\t\t)\n",
    "\t\t# item[\"chunk_vector\"] = generate_embeddings_openai(item[\"chunk\"], client)\n",
    "\t\tlist1.append(item)\n",
    "\tdocument_list=[Document(page_content=doc['page_content'],metadata=doc['metadata']) for doc in list1]\n",
    "\treturn document_list,chunk_ids\n",
    "\n",
    "\n",
    "# search_client=elastic_search_client()\n",
    "from langchain_community.embeddings import JinaEmbeddings\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize the model\n",
    "embeddings = JinaEmbeddings(jina_api_key=\"jina_2332cca0b8cc401eac7c37b5fb11fbf7pVCt3u2J1pcxQJrm6RY3aJgFHEAw\", \n",
    "\t\t\t\t\t\t\t\t\tmodel_name=\"jina-clip-v1\")\n",
    "\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "\n",
    "def retrieval():\n",
    "\ttemp_folder=\"uploads\"\n",
    "\tdestination_directory=\"document\"\n",
    "\tif os.path.exists(temp_folder):\n",
    "\t\tlist_files=os.listdir(temp_folder)\n",
    "\t\tprint(\"No. of Files Detected ::\",len(list_files))\n",
    "\n",
    "\tfor file_name in list_files:\n",
    "\t\tprint(file_name)\n",
    "\t\tfile_path=temp_folder+f\"\\{file_name}\"\n",
    "\t\tchunks=document_retrieval_chunking(file_path) # document_list,chunk_ids\n",
    "\t\tdocument_list,chunk_ids=chunk_processing(chunks,file_name,\"dummay\")\n",
    "\t\tuuids = [str(uuid4()) for _ in range(len(document_list))]\n",
    "\t\t## Add File Vectors to the elastic search\n",
    "\t\tvector_store.add_documents(documents=document_list, ids=uuids)\n",
    "\t\tstatus=1\n",
    "\t\n",
    "\t\tsource_path = os.path.join(temp_folder, file_name)\n",
    "\t\tdestination_path = os.path.join(destination_directory, file_name)\n",
    "\t\tshutil.move(source_path, destination_path)\n",
    "\t\tprint(f'Moved: {file_name}')\n",
    "\t\tprint(\"Document Chunking, Indexing and Uploaded to Elastic Search Succesfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Files Detected :: 1\n",
      "01_Sean-Yang(TrendForce)_NAND-Flash-Market-Outlook.pdf\n",
      "--------------PDF FILE DETECTED-------------\n",
      "[<unstructured.documents.elements.CompositeElement object at 0x0000019C73EE9390>, <unstructured.documents.elements.CompositeElement object at 0x0000019C73EE8880>, <unstructured.documents.elements.CompositeElement object at 0x0000019C73EE9090>, <unstructured.documents.elements.CompositeElement object at 0x0000019C73EEA590>, <unstructured.documents.elements.CompositeElement object at 0x0000019C85003010>, <unstructured.documents.elements.CompositeElement object at 0x0000019C84FE3F10>, <unstructured.documents.elements.CompositeElement object at 0x0000019C73EEAF80>, <unstructured.documents.elements.CompositeElement object at 0x0000019C80439C90>, <unstructured.documents.elements.CompositeElement object at 0x0000019C73EEB880>, <unstructured.documents.elements.CompositeElement object at 0x0000019C8043A5C0>, <unstructured.documents.elements.CompositeElement object at 0x0000019C73EE8A00>]\n",
      "Moved: 01_Sean-Yang(TrendForce)_NAND-Flash-Market-Outlook.pdf\n",
      "Document Chunking, Indexing and Uploaded to Elastic Search Succesfully\n"
     ]
    }
   ],
   "source": [
    "retrieval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector_store = FAISS.load_local(\n",
    "    \"faiss_index\", embeddings, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = new_vector_store.similarity_search(\"Supply Dynamics: Limited Growth &Constant Share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_string=eval(docs[1].metadata['images_info'])[6]['image_base64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABKAboDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDyKinU2vVOMKSlopANPSkp9JQA2inUhoASmnrTqKBjabUlNoAbRTqD0oAZiiloNAxppKdSGhgJSgDHSkopAGKb3p1GM0ANop22m0ANop2MU3vQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBoUU7BoqiENptOwaMGgGNopxBxTcGgaA0lLg0UgEpD1p1JQA2inUmKAEptOxRQA09KbUh6UmKBjKDTiPSm4NAxKKWkoAbto6dKdSYNDATJoopOaQAelNNPPSm4NADcetHFOK5pCuKAEooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKANSkxS4oqiBMUlOpMUAIaTFOxSYoGhuMUhGacRmjFADcUhHNOpCKAG4oxS0UgEpMUtFACYpKcabigBCM0YpaKAGEc0lPIppHNA0JSU7FJQMbijFLiihgJikpxpp4pAFIaM0daAGkUYp2KSgBtFKetJQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBq0lOxzS4qiBmKMU7FJQAlB5paSgBMUhGKdRjNADCM0lONJigdxuKMU7FGKBDKTFOxRigY3FBFLRSAbikIxTqMZoAbSYp2KQ0AJim45p9JigBuKSnUmKBobRS0YoGNxQaWkNACUmKWikAmKaRzT+KTFADcUlPxTSMUAJRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAbGKMUtFUQJjim4p9NoAQjikxSnpSUAJRQaKADFJilooAbRR3ooATFBHFLQelAxmKCKWkPSkAlJS0hoAKTFLRQA2ijvRQAmKMcUtHagBmKCKWkPSgpCUlLSGgAPNJilopANI5ooPWigApCKWlPQ0AR4oIpaQ9KAEooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "from IPython.display import display, Image\n",
    "\n",
    "image_bytes = base64.b64decode(base64_string)\n",
    "\n",
    "display(Image(data=image_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "import pandas as pd\n",
    "import json\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import mimetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_client = Minio(\n",
    "    \"4.240.104.16:9000\",  # MinIO server hosted at your URL\n",
    "    access_key=\"qjaIb6kmOspGolVOTmYC\",\n",
    "    secret_key=\"xNb2BC5NJlwc42HYjGyQLMyvfoSnQi7qNXAPtlKE\",\n",
    "    secure=False  # Change to True if using HTTPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload any file\n",
    "def upload_file(bucket_name, object_name, file_path):\n",
    "    content_type, _ = mimetypes.guess_type(file_path)\n",
    "    if content_type is None:\n",
    "        content_type = \"application/octet-stream\"  # Default content type for unknown files\n",
    "    \n",
    "    minio_client.fput_object(bucket_name, object_name, file_path, content_type=content_type)\n",
    "    print(f\"File {object_name} uploaded successfully to {bucket_name} with content type {content_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File hr_hr_Attention.pdf uploaded successfully to documents with content type application/pdf\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "bucket_name = \"documents\"\n",
    "\n",
    "# Upload different types of files\n",
    "upload_file(bucket_name, \"hr_hr_Attention.pdf\", \"document//01_Sean-Yang(TrendForce)_NAND-Flash-Market-Outlook.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
